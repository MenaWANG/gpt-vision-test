{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📸 True or False Recognition Demo\n",
    "\n",
    "The purpose of this demo is a minimalist test of GPT-4's workflow in document recognition tasks. The code in this notebook accomplishes the tasks below:\n",
    "\n",
    "- 🖼️ Submit an image of a document to the GPT-4 model.\n",
    "- 🧪 True/False classification : Receive a response indicating whether the document appears to be a certain type or contains certain content.\n",
    "- 📝 Details: Get additional details or insights about the document based on the model's analysis.\n",
    "\n",
    "Let's get started. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from mimetypes import guess_type\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "Encode a local image into base64 format and generating a data URL for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    base64_encoded_data = encode_image(image_path)\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "image_path = \"images/dummy-receipt1.png\"\n",
    "\n",
    "# Getting the data path\n",
    "data_url = local_image_to_data_url(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Input Payload\n",
    "\n",
    "Payload structure for submitting an image and a True/False question to the GPT-4 model, along with user role specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "  \"model\": \"gpt-4-turbo\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Is this a receipt of healthcare service? Pls start your response with True or False, then offer your reasoning in 1-2 setences.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300 # Remember to set a \"max_tokens\" value, or the return output will be cut off.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Request Execution\n",
    "Send a POST request to the model endpoint with the specified headers and payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use OpenAI API endpoint when AZURE_ENDPOINT is not specified\n",
    "post_url = os.getenv(\"AZURE_ENDPOINT\", \"https://api.openai.com/v1/chat/completions\")\n",
    "\n",
    "# Option 2: AZURE_ENDPOINT, specify in .env\n",
    "# post_url = f\"https://{RESOURCE_NAME}.openai.azure.com/openai/deployments/{DEPLOYMENT_NAME}/extensions/chat/completions?api-version=2023-12-01-preview\"\n",
    "# RESOURCE_NAME is the name of your Azure OpenAI resource\n",
    "# DEPLOYMENT_NAME is the name of your GPT-4 Turbo with Vision model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.post(post_url, headers=headers, json=payload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and Print Information\n",
    "Extract relevant information from the model response and print it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcare service receipt: False\n",
      "Details: This is not a receipt of healthcare service; it appears to be a receipt for automotive parts and service, with items such as \"Front and rear brake cables\" and \"New set of pedal arms\" listed, which are typical in vehicle maintenance.\n"
     ]
    }
   ],
   "source": [
    "response_data = response.json()\n",
    "\n",
    "# Format the full response\n",
    "full_response = json.dumps(response_data, indent=4)\n",
    "\n",
    "# Extracting true or false from the response\n",
    "is_healthcare_receipt = response_data['choices'][0]['message']['content'].startswith('True')\n",
    "\n",
    "# Extracting details from the response\n",
    "content_split = response_data['choices'][0]['message']['content'].split('. ')\n",
    "details = content_split[1] if len(content_split) > 1 else \"\"\n",
    "\n",
    "\n",
    "# Printing the extracted information\n",
    "print(\"Healthcare service receipt:\", is_healthcare_receipt)\n",
    "print(\"Details:\", details)\n",
    "# print(\"Full response:\", full_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
